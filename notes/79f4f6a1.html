<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>50分钟破除AI焦虑 掌握底层逻辑</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.8;
            color: #333;
        }
        h1 {
            border-bottom: 2px solid #eee;
            padding-bottom: 10px;
        }
        .meta {
            color: #666;
            font-size: 0.9em;
            margin-bottom: 20px;
        }
        .summary {
            background-color: #f6f8fa;
            border-left: 4px solid #0366d6;
            padding: 15px;
            margin: 20px 0;
            border-radius: 0 8px 8px 0;
        }
        .summary-title {
            font-weight: bold;
            margin-bottom: 8px;
            color: #0366d6;
        }
        .content {
            white-space: pre-wrap;
            word-wrap: break-word;
        }
        .back-link {
            margin-top: 30px;
            padding-top: 20px;
            border-top: 1px solid #eee;
        }
        .back-link a {
            text-decoration: none;
            color: #0366d6;
        }
    </style>
</head>
<body>
    <h1>50分钟破除AI焦虑 掌握底层逻辑</h1>
    <div class="meta">
        <p><strong>原始链接：</strong><a href="https://v.douyin.com/nZL1EpoHQ7o/" target="_blank">https://v.douyin.com/nZL1EpoHQ7o/</a></p>
        <p><strong>任务ID：</strong>ebf02019</p>
        <p><strong>日期：</strong>2026-02-22</p>
    </div>
    <div class="summary">
        <div class="summary-title">💡 AI总结</div>
        <div>
这是一个50分钟的AI大模型科普系列视频，由"林粒粒呀"讲解。内容涵盖了AI、AIGC、生成式AI、机器学习、监督学习、无监督学习、强化学习、深度学习、大语言模型等核心概念的关系和区别。

视频详细讲解了：
1. AI相关技术词汇的关系图谱
2. Transformer架构和自注意力机制
3. 大语言模型的工作原理（文字接龙）
4. ChatGPT的训练三步骤（预训练、监督微调、强化学习）
5. 提示工程和思维链
6. RAG检索增强生成、程序辅助语言模型、ReAct框架等外挂技术

作者强调，真正让人焦虑的不是AI变化太快，而是对它的理解太少。理解了背后的原理，就能以不变应万变。</div>
    </div>
    <div class="content">
50分钟帮你破除A焦虑，掌握底层逻辑这几年，新的A产品一个接一个出现，每周都会冒出新模型、新工具、新名词。很多人学着学着开始焦虑，是不是又没个上，是不是刚学会的东西又要过时了。但真正让人焦虑的并不是A变化太快，而是我们对它的理解太少。如果我们只是在挤工具的用法，那永远追不上版本的更新。但如果理解了背后的原理，就会发现大量变化的表象之下是稳定的技术逻辑，一旦看清这些内核，任何频繁更新也不会再让你焦虑。Hello喽，我是莉莉，千万播放课程讲师，前亚马逊程序员，这个人人都能懂的AI大模型科普系列，不会教你写代码，也不需要计算机背景，我会用几个5到10分钟通俗直观的短视频帮你建立对A底层逻辑的了解，让你以不变应万变。但理解原理之后，你也会看懂很多现象，比如为什么模型有时会一本正经胡说八道，为什么数学运算得不到准确结果，如何调教出个性化模型等等。与其被动适应工具，不如主动驾驭工具。如果你不想一直被新技术追着跑，而是希望拥有稳定、长期、有效的理解框架，记得把这个系列先收藏起来。我们下个视频见AI声称是AI、AI之系，机器学习、监督学习、无监督学习、强化学习、深度学习、大于模型，这词都是啥，欢迎收看人人都能懂的AI大模型课，普课第一皆知，带你分清一堆AI相关技术词。说起近几年的热门科技词汇，AI之C当之无愧位列其中。但你真的了解AI c吗？从某一天开始，我们突然发现AI可以帮忙生成文字、图片、音频、视频等等内容了，而且让人难以分清背后的创作者到底是人类还是A I却些AI生成的内容被叫做AI c它是AI generated content，即AI生成内容的简写，像deep sick生成的文章、free生成的代码、积目生成的图片等等，都属于aic。而当aic这个词在国内火爆的同时，海外更流行的是另外一个词generative AI既生成是A I从字面上来看，生成式AI和AI这之间的关系很好理解，生成式AI所生成的内容就是AIGC，所以呢，deep sick tree、吉梦，还有数字的豆包、元宝、可伶都属于声称是AI。由此可见，AI g see和生成式AI的概念都是很简单直白的，但因为AIGC这个词在国内比生成式AI更加流行，很多语境下，AI c也被用于指代生成式A I，那么生成式AI和AI。机器学习、监督学习、无监督学习、强化学习、深度学习、大元模型等等词汇之间又是什么关系呢，有没有种剪不断理还乱的感觉，这个很难一言以蔽之，但通过一张图就可以直观理解它们之间的关系了。AI也叫人工智能，是计算机科学下的一个学科，旨在让计算机系统去模拟人类的智能，从而解决问题和完成任务。早在1956年，AI就被确立为了一个学科领域，在此后数十年间经历过多轮低谷与繁荣。机器学习是AI的一个子集，它的核心在于不需要人类做显示编程，而上计算机通过算法自行学习和改进去识别模式，做出预测和决策。比如如果我们通过代码告诉电脑，图片里有红色说明是玫瑰，图片里有橙色说明是向日葵，那程序对花种类的判断就是通过人类直接明确编写逻辑达成的，不属于机器学习，机器骂也没学。但如果我们给电脑大量玫瑰和向日葵的图片，让电脑自行识别模式，总结规律，从而能对没见过的图片进行预测和判断，这种就是机器学习。机器学习领域下有多个分支，包括监督学习、无监督学习、强化学习。在监督学习里，机器学习算法会接受有标签的训练数据，标签就是期望的输出值。所以每个训练数据点都既包括输入特征，也包括期望的输出值。算法的目标是学习输入和输出之间的映射关系，从而在给定新的输入特征后，能够准确预测出相应的输出值。经典的监督学习任务包括分类，也就是把数据划分为不同的类别以及回归，也就是对数值进行预测。比如拿蚁对猫猫狗狗的照片和照片对应的猫狗标签进行训练，然后让模型根据没见过的照片预测是猫还是狗，这就属于分类。拿一些房子特征的数据，比如面积、卧室、树是否带阳台等，和相应的房价作为标签进行训练，然后让模型根据没见过的房子的特征预测房价，这就属于回归。无监督学习，和监督学习不同的是，他学习的数据是没有标签的，所以算法的任务是自主发现数据里的模式和规律。经典的无监督学习任务包括聚类，也就是把数据进行分组。比如拿一堆新闻文章，让模型根据主题或内容的特征自动把相似文章进行组织，而强化学习则是让模型在环境里采取行动，获得结果反馈，从反馈里学习，从而能在给定情况下采取最佳行动来最大化奖励或是最小化损失。所以就跟训小狗似的，刚开始的时候小狗会随心所欲做出很多动作，但随着和训犬时的互动，小狗会发现某些动作能够获得零食，某些动作没有零食，某些动作甚至会遭受惩罚。通过观察动作和奖惩之间的联系，小狗的行为会逐渐接近训犬师的期望。强化学习可以应用在很多任务上，比如说让模型下围棋，获得不同行动导致的奖励或损失反馈，从而在一局局游戏里优化策略，学习如何采取行动达到高分。那问题来了，深度学习属于这三类里的哪一类呢？它不属于里面的任何一类。深度学习是机器学习的一个方法，核心在于使用人工神经网络模仿人脑处理信息的方式，通过层次化的方法提取和表示数据的特征。神经网络是由许多基本的计算和储存单元组成，这些单元被称为神经元，这些神经元通过层层连接来处理数据。并且深度学习模型通常有很多层，因此称为深度。比如要让计算机识别小猫的照片，在深度学习中，数据首先被传递到一个输入层，就像人类的眼睛看到图片一样。然后数据通过多个隐藏层，每一层都会对数据进行一些复杂的数学运算，来帮助计算机理解图片中的特征，例如小猫的耳朵、眼睛等等，最后计算机会输出一个答案，表明这是否是一张小猫的图片。神经网络可以用于监督学习、无监督学习、强化学习，所以深度学习不属于它们的子集。双城式AI是深度学习的一种应用，它利用神经网络来识别现有内容的模式和结构，学习生成新的内容，内容形式可以是文本、图片、音频等等。而大语言模型也叫llm language language model，也是深度学习的一种应用，专门用于进行自然语言处理任务。大语言模型里面的大字说明模型的参数量非常大，可能有数十亿甚至到万亿个，而且训练过程中也需要海量文本数据集，所以能更好地理解自然语言以及生成高质量的文本。大语言模型的例子有非常多，比如国外的GPT cloud、国内的tipsi困等，可以进行文本的理解和生成。以g 3这个模型为例子，它会根据输入提示以及前面生成过的词，通过概率计算逐步生成下一个词或头肯来输出文本序列，想对大语言模型背后的原理有更多了解的话，可以收看下一节视频。但不是所有的生成式AI都是大语言模型，而所有的大语言模型是否都是生成式AI这也存在些许争议。前半句很好理解，声成图像的扩散模型就不是大语言模型，它并不输出文本。同时，有些人认为，不是所有大语言模型都是生成式A I，这是因为有些大语模型由于其架构特点不适合进行文本生成。谷歌的Bert模型就是一个例子，它的参数量和训练数据很大，属于大语言模型应用方面，Bert理解上下文的能力很强，因此被谷歌用在搜索上，用来提高搜索排名和信息摘录的准确性，它也被用于情感分析、文本分类等任务。但同时贝不擅长文本生成，特别是连贯的长文本生成，所以有些人认为此类模型不属于生成式A的范畴。这些概念共同构成了生成式AI的核心要素，希望能帮助你对时下热门的AI c建立更多了解，下一节里我们会更深入的探索大语言模型，我们下个视频见。揭秘豆包、deep chat、gp等AI工具背后的神秘力量大约模型啥是大圆模型呢？大圆模型也叫llm H language model，是用于做自然语言相关任务的深度学习模型，给模型一些文本内容输入，它能返回相应的输出，完成的具体任务可以是生成、分类、总结、改写等等。大源模型首先需要通过大量文本进行无监督学习。以GPT三为例，它的训练数据有多个互联网文本语料库，覆盖线上书籍、新闻文章、科学论文、维基百科、社交媒体帖子等等。借助海量的训练文本数据，模型能更多了解单词与上下文之间的关系，从而更好的理解文本的含义，并生成更准确的预测。但大语言模型的大指的不仅仅是训练数据巨大，而是参数数量巨大。参数是模型内部的变量，可以理解为是模型在训练过程中学到的知识。参数决定了模型如何对输入数据做出反应，从而决定模型的行为。在过去的语言模型研究中发现，用更多的数据和算力来训练具有更多参数的模型，很多时候能带来更好的模型表现。这就像要AI学习做蛋糕，只允许AI调整面粉、糖蛋的量和允许AI调整面粉、糖蛋、奶油、牛奶、苏打粉、可可粉的量以及烤箱的时长和温度。后者由于可以调整的变量更多，更能让AI模仿做出更好吃的蛋糕，随着参数的增加，他甚至有能力做出别的玩意儿，创造一些全新的品种，所以如今语言模型的参数数量可能是曾经的数万倍甚至数百万倍。以open eye的第一个大模型GPT一为例，它有1.17亿个参数，到了GPT 2，参数有15亿个，而GPT三的参数又增长到了1750亿个，这让大模型不像小模型那样局限于单项或某几项任务，而是具有更加广泛的能力。比如在这之前，我们可能要训练单独的模型，分别去做总结、分类、提取等等任务，但现在一个大模型就可以搞定这一切，像杜包、deep、千问、chgcloud等AI聊天助手都是基于单元模型的应用。如果说2022年年底，chat g的经验亮相，是大元模型公众认知被显著提升的里程碑，那它技术发展的里程碑其实要回溯到2017年，2017年6月，谷歌团队发表论文attention its all unit提出了transformer架构。自此，自然语言处理的发展方向被改变了，随后出现了一系列基于transformer架构的模型，2018年OpenAI发布g 1.0，谷歌发布Bert，2019年OpenAI发布g 2.0，百度发布1.0等等，所以大语言模型的发展早就如火如荼了。并不是像很多人以为的到了2022年才有所突破，但因为拆了g直接向公众开放，而且能让用户在网页上用对话的方式进行交互，体验很流畅丝滑，大众的目光才被吸引过去。Chat g背后的模型g首字母分别表示generpretransformer生成是预训练transformer，也表明transformer是其中的关键，所以要了解大语言模型就无法跳过transformer，在transformer架构被提出之前，语言模型的主流架构主要是循环神经网络，简称rr按. 顺序逐字处理，每一步的输出取决于先前的隐藏状态和当前的输入，要等上一个步骤完成后才能进行当前的计算，因此无法变形计算训练效率低，而且呢不擅长处理长序列，也就是长文本。由于R的架构特点，此时间距离越远，前面对后面的影响越弱，所以它难以有效捕获到长距离的语义关系，但在人类自然源中，依赖信息之间距离较远是很常见的情况，比如这句话里正确预测下一个词的关键是距离很远的广东。如果由R生成后续内容到了这里的时候，它可能已经把前面的信息忘没了。为了捕获长距离依赖性，后来也出现了rn的改良版本lstm长短期记忆网络，但是这也并没有解决传统rn无法并行计算的问题，而且在处理非常长的序列时也依然受到限制。后来transformer他这七彩相遇出现了，它有能力学习输入序列里所有词的相关性和上下文，不会受到短时记忆的影响。能做到这一点的关键在于transformer的自注意力机制，也正如论文标题所说，attention is all you need, 注意力就是你所需要的一切，简单来说，transformer在处理每个词的时候，不仅会注意这个词本身以及它附近的词，还会去注意输入序列里所有其他的词，然后其余每个词不一样的注意力。权重权重是模型在训练过程中通过大量文本逐渐习得的，因此transformer有能力知道当前这个词和其他词之间的相关性有多强，然后去专注于输入里真正重要的部分。即使两个词的位置隔得很远，transformer依然可以捕获到它们之间的依赖关系，比如这个例子，单从语法上来讲，it可以指的是离得更近的street，也可以是离得更远的animal，这里自助力机制捕获到了it和animal之间更强的关系，因此更集中在animal上。除了自注意力机制，transform的另一项关键创新是位置编码。在语言里，顺序很重要，即使句子里包含的字都是一样的，但顺序不一样也能导致意思大相径庭，这也是为什么自然语言处理领域会用序列这个词，因为它表示一系列按照特定顺序排序的元素，前面提到和人类阅读文本一样，对输入序列同样是按顺序依次处理，这就造成了训练速度的瓶颈，因为只能串行，没办法并行，也就是没法同时去学习所有信息。Transformer呢在把词输入给神经网络前，除了会先对词进行嵌入转换成向量，也就是把词各用一串数字表示，还会把每个词在句子中的位置也各用一串数字表示添加到输入序列的表示中，然后把这个结果给神经网络。那模型既可以理解每个词的意义，又能够捕获词在句子中的位置，从而理解不同词之间的顺序关系，借助位置编码，词可以不按顺序输入，给transform模型可以同时处理输入序列里的所有位置。而不需要像rn那样依次处理，那么在计算时，每个输出都可以独立的计算，不需要等待其他位置的计算结果，这大大提高了训练速度，训练速度一快，训练出巨大的模型也不是那么难了。自attention is all you need。Fi之后，transformer以及它的变体已经被普遍运用在大型数据集上来训练大语言模型，所以呢transformer架构对我们当下能拥有那么多牛叉的大语言模型功不可没。如果你好奇transformer具体是如何工作的，以及chat g背后的g模型是如何生成文本的，下一节会有详细的介绍，揭秘豆包deep g等AI工具背后的原理，简单来说就是四个字，文字接龙，更准确的说，它们是通过预测出现概率最高的下一个词来实现文本生成的。这种效果有点像搜索引擎的自动补全，每当我们输入一个新的字或词输入框，就开始预测后面的文本概率越高的排在越上面，但模型具体到底是如何得到各个词出现的概率呢？这个视频为你揭秘豆包对chat gt等工具背后的原理在上一个介绍大语言模型的视频里我们提到，说起大语言模型的技术原理，就不得不说transformer架构，自从一篇2017的论文attention is all you提出transformer后，文本领域的大模型几乎被它一统江湖。Open g侵、华的、百度的only等等，背后无一没有transformer的影子。在attention is all you need的论文里，它长成这样，看起来有点复杂，但不需要头戴，它可以被看作由两个核心部分组成，编码器encoder以及解码器decder。假如我们要这个transformer做英语翻译法语的任务，给编码器输入一句英语，解码器返回对应的法语，这个过程中发生了什么呢？我们先看编码器部分输入的文本首先会被token化，也就是先把输入拆分成各个token，token可以被理解为是文本的一个基本单位，取决于不同的token化方法。短单词可能每个词是一个token，长单词可能被拆成多个token。然后呢，每个token会被用一个整数数字表示，这个数字被叫做token ID。这样做是因为计算机内部是无法储存文字的，任何字符最终都得用数字来表示。有了数字表示的输入文本后，再把它传入嵌入层。嵌入层的作用是让每个token都用向量表示，向量可以被简单的看为一串数字，为了能在画面里放下，这里把向量长度简化为三，但实际中向量长度可以非常长。问题来了，之前明明已经用单个整数表示各个token了，怎么现在又要用一串数字表示各个偷Ken？其中一个原因是一串数字能表达的含义是大于1个数字的，能包含更多语法、语义、信息等等。这就好比男人和女人这两个词，它们都在描述人类，但性别又是完全相反的。如果只用一个数字表示，这两个数字大小之间应该距离很大，还是应该距离很小呢？但如果有多个数字，我们就可以进行更多维度的表示。就比如说第一个数字可以表示是磁性的程度，第二个表示年龄大的程度，第三个表示社会阶层高的程度。所以呢嵌入层的向量不是随便搞出来的，里面包含了词汇之间语法、语义等关系相似的词所对应的嵌入向量，在向量空间里距离也更近，而一些没啥关系的词之间的距离就更远。这有助于模型利用数学计算向量空间里的距离去捕捉不同词在语义和语法等方面的相似性，而且呢男人与国王的差异和女人与女王的差异可以被看作是相似的，这也可以在多维向量空间里展现。因此词向量不仅可以帮模型理解词的语义，也可以捕捉词与词之间的复杂关系。那我们这里为了直观是用三维向量空间表示的，把向量长度相应简化成了3，而提出全方位的论文里向量长度是512，这比3是12288。所以可以想象能包含多少信息。通过编码器的嵌入层得到磁向量后，下一步是对向量进行位置编码。我们在上个视频里提到trans位的一项关键机制是位置编码，如果你没看上一节，没关系。位置编码就是把表示各个词在文本里顺序的向量和上一步得到的词向量相加，然后把得到的结果传给编码器。这样做的意义是模型既可以理解每个词的意义，又能够捕捉词在句子中的位置，从而理解不同词之间的顺序关系。接下来就到了编码器这个核心部分，它的主要任务是把输入转换成一种更抽象的表示形式。这个表示形式也是向量记串数字里面既保留了输入文本的词汇信息和顺序关系，也捕捉了语法语义上的关键特征，捕捉关键特征的核心是编码器的自注意力机制，模型在处理每个词的时候，不仅会关注这个词本身和它附近的词，还会关注输入序列中所有其他词。也正如transformer论文标题所说，attention is all you need, 注意力就是你所需要的一切，自注意力机制通过计算每对词之间的相关性来决定注意力权重，如果两个词之间的相关性更强，它们之间的注意力权重就会更高。比如这个例子，单从语法上来讲，it可animal也可以指street，而自注力机制发现了it与animal更强的关联，所以给animal的权重会更大一些。但由于自助力机制对上下文的全面关注，但在输出的表示结果里，不仅包含这个词本身的信息，还融合了上下文中的相关信息。上下文在语言里很重要，也能揭露相同词的不同含义，所以在解码器输出的结果里，表示各个词的向量会根据上下文信息进行调整，同一个词根据上下文有不同的抽象，表示。自助意力机制涉及到很多计算步骤，这个视频主要是做个简单的科普，更多细节可以在论文原文里关注一下。而且transformer实际上使用了多头自注意力，也就是编码器不只有一个自注意力模块，而是有多个，每个头都有它自己的注意力权重，用来关注文本里不同特征或方面，比如有的关注动词，有的关注修饰词，有的关注情感，有的关注命名实体等等。而且它们之间可以做并行运算，也就是计算进展上互不影响。每个自注意力头的权重都是模型在之前的训练过程中，从大量文本里逐渐学习和调整的。在多头字注意力后面还有一个前馈神经网络，它会对自注意力模块的输出进行进一步的处理，增强模型的表达能力。那编码器在transform里不止有一个，实际上是有多个堆叠到一起，每个编码器内部结构一样，但不共享权重。这样模型能更深入的理解数据处理，更复杂的文本语言内容。看完编码器，接下来看解码器的部分，它是大语言模型生成一个个词的关键。通过前面的编码器，我们有了输入序列里各个偷Ken的抽象表示，可以把它传给解码器。解码器还会先接收一个特殊值，这个值表示输出序列的开头，这样做的原因是解码器不仅会把来自编码器的输入序列的抽象表示作为输入，还会把之前已经生成的文本也作为输入，来保持输出的连贯性和上下文相关性。刚开始的阵轮还没有任何已生成的文本，所以把表示开头的特殊值先作为输入。具体的生成过程仍然是要经过多个步骤。首先和编码器一样，文本要经过我们已经了解过的嵌入层和位置编码，然后被输入进多头自注一力层。但它和编码器里的自注义层有点不一样，当编码器在处理各个词的时候，它会关注输入序列里所有其他词，但解码器中自助力只会关注这个词和它前面的其他词，后面的词要被遮住，不去关注。这样做是为了确保解码器生成文本时遵循正确的时间顺序，不能给它偷看到后面，在预测下一个词时只使用前面的词作为上下文，这种类型的多头字注意力被叫做带掩码的多头字注意力。但野码的多头字注意力是针对已生成的输出序列的，而那后面解码器还有个多头字注意力层，这里就是前面编码器所输出的输入序列的抽象表示所排上用场的地方，注意力会捕捉编码器的输出和解码器即将生成的输出之间的对应关系，从而将原始输入序列的信息融合到输出序列的生成过程中。解码器里的前馈神经网络作用和编码器里的类似，也是通过额外的计算来增强模型的表达能力。而且和编码器一样，解码器同样是多个堆叠到一起的，这可以增加模型的性能，有助于处理复杂的输入输出关系。解码器的最后阶段包含一个线性层和一个soft max层，它们俩加一块的作用是把解码器输出的表示转换为词汇表的概率分布。这个词汇表的概率分布代表下一个被生成偷坑的概率，那么有些偷坑的概率就会比其他的高。在大多数情况下，模型会选择概率最高的偷坑作为下一个输出。那现在我们知道了解码器本质上是在猜下一个最可能的输出，至于输出是否符合客观事实，模型无从得知，所以我们能经常看到模型一本正经的胡说八道，这种现象也被叫做幻觉，那解码器的一整个流程会重复多次，新的token会持续生成，直到生成的是一个用来表示输出序列结束的特殊token，那现在我们就拥有了来自解码器的完整输出序列。但以上描述的是attention is all里的原始transformer，编码器用来理解和表示输入序列，解码器用来生成输出序列，实际上在原始架构的基础上，后续出现了一些变种，主要有三个类别，仅编码器、仅解码器以及编码器。解码器仅编码器模型也叫自编码器模型，只保留了原始架构里的编码器，but就是这种模型的一个例子。此类模型适用于理解语言的任务，比如掩码语言建模，也就是让模型猜文本里被遮出的词是什么。情感分析，让模型判断文本情感是积极还是消极等等。仅解码器模型也叫自回归模型，只保留了原始架构里的解码器。Gp系列都是这种模型的例子，这类模型非常擅长通过预测下一个词来实现文本生成，我们已经在chat g身上建设过了编码器解码器模型也叫序列到序列模型，同时保留了原始架构里的编码器和解码器，T5 bar都是这种模型的例子，此类模型适用于把一个序列转换成另一个序列的任务，比如翻译、总结等等。那经过这个视频，你对大圆模型背后技术的了解，应该已经超过99%的人了，如果你好奇怎样才能练成一个chat gp的话，我们下个视频见，把大象装进冰箱只需要散步。要得到一个chat的g拢共分几步？也是三步。第一步，通过大量大量的文本进行无监督学习与训练，得到一个能进行文本生成的基座模型。第二步，通过一些人类撰写的高质量对话数据，对基座模型进行监督微调，得到一个微调后的模型。此时的模型除了续写文本之外，也会具备更好的对话能力。第三步，用问题和多个对应回答的数据，让人类标注员对回答进行质量排序，然后基于这些数据训练出一个能对回答进行评分预测的奖励模型，接下来让第二步得到的模型对问题生成回答，用奖励模型给回答进行评分，利用评分作为反馈进行强化学习训练。就这样chat的gt就被练成了，你学会了吗？那如果你想了解更详细的步骤，就继续观看吧。在第一步的预训练中，首先需要海量文本作为原料，让模型从中学习。比如GPT三这个基座模型的训练数据有多个互联网文本语料库覆盖书籍、新闻文章、科学论文、维基百科、社交媒体帖子等等，训练数据的整体规模是3000亿的头Ken，如果你不了解什么是头Ken的话，它一般指的是大语言模型的一个基本文本单位。像短的英文单词可能一个词是一个token，而长的词可能被分为多个token。而中文的话所占的token数量会相对更多，有些字要用一个甚至更多token表示。那回到我们的主题，有了大量可用于训练的文本后，要采用无监督学习的方式训练模型。和无监督学习相对的是，监督学习模型会接受有标签的训练数据，标签就是期望的输出值，所以每个训练数据点都既包括输入特征，也包括期望输出值。而无监督学习则是让模型在没有标签的数据上进行训练，所以模型要自己找出数据中的结构和模式。以知变三为例，训练过程中它会利用海量文本自行学习人类语言的语法语义，了解表达结构和模式。那具体来说，模型会先看到一部分文本，基于上下文尝试预测下一个头肯，然后通过比较正确答案和它的预测，模型会更新权重，从而逐渐能根据上文来生成合理的下文。并且随着建过的文本越来越多，它生成的能力也会越来越好。如果你对模型生成文本的内部细节感兴趣，可以收看我的上一个视频。那日训练并不是一个容易的过程，也是这四个步骤里最耗时费力烧钱的，以gp 3为例，虽然官方还没有公布准确数据，但大体估计它经过了数月的训练，用了成千上百个V 100季pu烧了几百万美元，日训练的结果是得到一个基座模型，基座模型并不等同于拆的gp背后的对话模型，因为此时模型有预测下一个偷坑的能力，会根据上文补充文本，但并不擅长对话。你给他一个问题，他可能模仿尚文帮你继续生成更多的问题，但不回答你的问题。为了解决这点，我们需要进行第二步，对基座模型进行微调。微调就是在已有模型上做进一步的训练，会改变模型的内部参数，让模型更加适应特定任务。换句话说，为了训练出一个擅长对话的AI助手，需要给基座模型看更多的对话数据，但微调的成本相比预训练低很多，因为需要的训练数据规模更小，训练时长更短。在这一阶段里，模型不需要从海量文本学习了，而是从一些人类写的专业且高质量的对话里学习，这相当于既给了模型问题，也给了模型我们人类中意的回答，属于监督学习，所以这一过程被叫做监督微调supervifine tun简称S F T完成后会得到一个s模型，它与步骤一里的基座模型更加擅长对问题做出回答，但为了让模型的实力继续被提升，还可以进行第三步，让s模型进行强化学习。强化学习是让模型在环境里采取行动，获得结果反馈，从反馈里学习，从而能在给定情况下采取最佳行动来最大化奖励，获最小化损失。所以就跟驯小狗似的，随着和驯犬师的互动，小狗会发现某些动作能获得零食，某些动作没有零食，某些动作甚至会遭受惩罚，通过观察动作和奖惩之间的联系，小狗的行为会逐渐接近驯犬师的期望。要让恰g的模型乖乖当一个乐于助人的AI助手也是一样的道理。我们可以让g对问题做出回答，然后让人类评估员去给回答打分。打分主要是基于3H原则，helpful有用性、honest真实性、harmless无害性，如果打分高的话，模型能学习到要再接再厉，如果打分低的话，模型就学习到要予以改正。但是靠人类给回答一个个打分成本极高，效率极低，那为何不训练出另一个模型，让模型给模型打分？所以在这一步骤里需要训练一个奖励模型，它是从回答以及回答对应的评分里学习的那得到评分数据的方式是让微调后的GPT模型，也就是第二步里得到的sft模型，对每个问题生成多个回答，然后让人类标注员对回答质量进行排序。虽然还是免不了要借助标注员的劳动，但一旦有了足够的排序数据，就可以把数据用在训练奖励模型上，让奖励模型学习预测回答的评分，奖励模型训练出来后，就可以用在强化学习上了。强化学习力chat gt模型的最初参数来自之前得到的s模型，但会随着训练被更新，奖励模型的参数则不再会被更新，它的任务就是对模型生成的内容打分。它经过一轮又一轮迭代后，模型会不断优化，策略回答的质量会进一步提升，强大的ChatGPT就在不断学习中练成了。后来的故事我们都知道了。2022年11月，chat g对外发布，至此引爆生成式AI元年。那如果这个视频对你有帮助的话，也求高抬贵手点个赞，下一节里我们会一起了解如何正确调教豆包g等爱聊天助手，我们下个视频见。年末发现豆爆、deep、ck gt等恋爱聊天工具，有时候像个博览群书的天才，有时候像个喝了二郎酒的傻子。针对这种现象，越来越多人开始研究怎么调教出一个聪明的AI聊天助手。提示工程就是研究如何提高和AI的沟通质量及效率的核心，关注提示的开发和优化。提示就是我们给AI聊天助手输入的问题或指令，AI会根据提示内容给予回应。在进入提示工程之前，我们要先了解A聊天助手存在的局限性。它们背后的大语言模型是用海量文本训练出来的，因此擅长模仿人类语言表达，也从那些内容里学到了不少知识。他们的回应都是根据提示以及前面已生成的内容，通过持续预测下一个偷坑的概率来实现的。但同时对于他们不了解的领域，他们并不知道自己缺乏那方面的知识，仍然在德表的同时使教材后面应该说什么，加上生成过程中也没有反思能力，所以我会经常看到胡说八道的同时还充满着自信。为了调教A给出想要的回答。第一个办法是用小样本提示，我们很多时候都是直接丢问题或指令给AI这种属于零样本提示，就是没有给AI任何示范，不一定和我们想要的效果相符。但如果我们让AI回答前给他几个对话作为示例，用样本对它进行引导，AI模型就会利用上下文学习能力，一方面记忆那些内容作为知识，另一方面像示范那样模仿着进行回应。有了小样本提示后，再问AI类似的问题，它就能给出和提示示范相似的回答了。小样本提示的另一个好处是，由于AI回应的内容风格会大概率遵循我们给的示范，我们也就不用多费口舌给AI提要求，可以让它自行从前面的示范回答里领悟。但小样本提示有时也起不到很大的作用，比如AI非常不擅长做数学相关问题，即使我们用样本示范一些正确的结果，到他做的时候依然掉链子。比如这个例子里面，所有奇数相加后的结果是41，不是三十七。但问题在于，AI生成每个token所用的时长是差不多的，不会因为某个词需要涉及更多的思考而花费更多时间生成那个token，所以计算结果就被它乱哈拉过去了，前面有正确的示范答案，也没有什么帮助。这种时候可以借助思维链，思维链最早是谷歌在2022年1篇论文里提出的，作者发现思维链可以显著提升大比言模型进行复杂推理的能力，特别是在算术常识和符号推理等任务上。运用思维链的方法是我们给AI的小样本，提示里不仅包含正确的结果，也展示中间的推理步骤。那A在生成回答时也会模仿着去生成一些中间步骤，把过程进行分解。这样做的好处是肚子小点不容易扯着，就像被老师点名回答问题时，站起来瞬间就给出正确答案的难度系数很高。但如果说多说些废话，把思考步骤也讲出来，一方面可以拖时间，有更多思考机会。另一方面也有助于我们分步骤想，更有机会得到正确答案。思维链也可以用在数学计算之外的很多方面。借助思维链A可以在每一步里把注意力集中在当前思考步骤上，减少上下文的过多干扰，因此针对复杂的任务有更大概率得到准确的结果。在思维列的相关论文里，作者还提到，即使我们不用小样本提示，只是在问题后面加一句let's think step by step，让我们来分步骤思考，也能提升AI得到正确答案的概率，这是一种成本非常低的方法。用思维链还需要我们想样本示范，而这种方法只需要加上简单一句话，AI就会自行生成中间步骤进行推理。来人福音你学会了吗？那还有更难的方法吗？有的，我们只需要在使用A聊天工具时点亮他们的深度思考模式。深度思考的背后是推理模型，比如open的OEO3、deep R一等等，这些模型会先在内部进行链式推理，再输出结果。所以我们可以看到模型给出回答前会先碎碎念一大段，在没有提示的情况下自行进行多步骤的思考、规划和验证。但推理模型并不是在普通模型基础上简单的加个请你分步骤思考的提示词，而是在训练阶段就专门被强化过多步推理能力，所以思维链是在教模型把思考过程写出来，而推理模型天生就具备分步骤思考的大脑。那如果想了解更多武装AI的办法，解决数据过时编造事实计算不准的问题，请见下回分解，我们下个视频见。当你AI工具用的够多，就会发现它们并不是无所不能的，而是有时编造式时偶尔计算翻车。聊起最近的新闻也会陷入迷茫，那怎么办？答案很简单，给它加上外挂，让模型在需要的时候去查资料，调用程序，借助外部知识，而不是只靠自己脑补。在技术圈里，这些方法都有自己的名字，比如碰这词是不是晦涩难懂，令人头大？没关系，我们一个个了解。AI大元模型所拥有的知识，受到训练数据的影响，如果训练数据里对某个领域的文本覆盖不多，AI学到的也不多，就没法很好的帮我们回答相关问题。因此，在小众细分领域上，AI的表现有可能不尽人意，而且像公司内部数据、个人私密文件等也都不可能作为公开大语言模型的训练数据，我们没法指望ChatGPT t能帮我们回答相关问题，怎么办呢？一个应对方法就是我们可以提供外部文档，让模型访问外部知识库，获得实时且正确的数据，生成更可靠和准确的回答，这种架构叫做检索增强生成retrieval augmented generation，简称rack。当我们把电脑上的文件上传到多包C g之类的AI工具，然后进行提问。会基于文件内容给出回答，这背后就是R机制在发挥作用。具体来说，外部知识文档要先被切分成一个个段落，因为大语言模型一次性能接收的文本长度有限，然后每个段落会被转换成一系列向量，向量可以被看作是一串固定长度的数字，然后储存进向量数据库里。当我们提出问题的时候，这个提示也会被转换为向量，然后查找向量数据库里和用户的查询向量最为接近的段落。向量找到以后，段落信息会和原本的用户查询问题组合到一起，一块传给AI这样AI就能把外部文档的段落作为上下文基余里面的信息给出更严谨的回答。因此你可以对外部文档里任何内容进行提问，即使AI模型从来没有收到过那些内容的训练，rag有利于搭建企业知识库或个人知识库。但元模型还有一个问题是，我们没法把它用作计算器。当我们问他一个数学计算后，他没有真正帮忙做计算，只是在猜下一个最可能出现的头肯来生成回答。根据之前对原理的了解，我们已经知道主流大约模型生成内容的过程，本质上就是持续猜下一个最可能出现的头肯。那当我们问他一个数学计算问题时，遵循同样的套路，他开始猜答案的第一个数字概率最高的是什么，第二个数字概率最高的是什么，以此类推，发现问题所在了吗，问题就是AI根本没有在做计算。但同时，因为大模型经过了大量文本训练，返回的数字答案看起来不会很离谱，所以很可能获得人类的信任。要知道，长得像巧克力的屎可比长得像屎的巧克力可怕多了。如果我们想让A充当网店客服，它虽能巧舌如簧的介绍产品，却也会告诉客户错误的订单总额，这很危险啊。但是如果我们不要它做计算，而是把计算后的结果告诉他呢？Programming added it language models程序辅助语言模型，简称pl可以帮助我们应对此类问题。它最早在2022年1篇论文里被提出p的核心在于我们不让AI直接生成计算结果，而是借助其他善于做计算的工具，比如Python解释器。那我们给AI的要求变成了在设计计算步骤时生成得到计算结果所需的代码，为什么这样做呢，因为大模型虽然精准计算的能力不行，但能很好的理解人类的需求。而且代码生成能力也不赖，那就让它根据人类的需求去生成解决问题所需的代码，然后拿到代码执行后的结果作为答案的一部分来生成回答。具体来说，首先为了让AI遵循我们的要求，可以借助思维链，如果你不了解思维链，可以看上一个视频，我们现在提示里通过小样本提示给模型示范如何分步骤思考，写出解决问题所需的变量赋值、数学运算等等代码，让模型照猫画虎。在用户提问后，把用户的问题和我们已有的提示模板进行拼接，一并给到AI，让AI生成代码。接下来把AI返回的回答给到拍档解释器，让拍档解释器执行并返回计算的结果，这个结果可以再给回到AI，让AI带着计算答案对用户的问题进行妥善回复。那相当于我们借用了大语言模型，接收问题的耳朵、思考的脑子、说话的嘴以及代码解释器做运算的手。目前一些聪明的AI工具会先判断问题是否涉及数学运算，涉及的话就自行编写和执行，判断代码得到正确答案。如果希望结果更可靠，我们也可以明确要求AI通过代码来计算数学问题。但无论如何，我们要随时保持警惕，问数学相关问题时记得留意AI有没有用代码工具AI大于模型还有一个局限性，那就是它所了解的知识天然受到训练数据日期的影响。比如说模型是去年训练完成的，训练数据里必然不包含今年的新闻，但模型也无从得知训练完成后发生的事情，这被称为知识阶段。那当我们问模型最近发生的事实时，模型要么会回复已经过时的信息，要么会胡编乱造一通，但重新训练模型的成本又是相当高的，也无法彻底解决数据过时的问题，如果A能对不了解的知识上网搜索，把找到的答案告诉我们就好了。为了解决这个局限，主流的AI工具大多提供了联网搜索功能，我们打开这个功能后，模型在回答问题前会先到互联网上搜索相关资料，然后结合搜索它的内容来生成答案，这样我们就可以问A实时信息了。但这背后发生了什么呢？A怎么知道要去浏览什么网站，浏览时应该关注什么关键词去查找相关信息呢？2022年，一篇标题为react在语言模型中协同推理与行动的论文提出了react框架。它不是热门前端框架那个react，而是reason和action推理与行动结合的意思。React的核心在于让模型进行动态推理，并采取行动与外界环境互动。它同样可以和思维链结合，我们会用小样本提示展示给模型一个推理与行动结合的框架，也就是针对问题把步骤进行拆分，每个步骤要经过推理行动观察。推理是针对问题或上一步观察的思考，行动是基于推理与外界环境的一些交互。比如用搜索引擎对关键字进行搜索，观察是对行动得到的结果进行查看。举个例子，如果问一个知识结顿在2024年7月的AI大运模型，2025年欧冠的冠军是哪个球队，它是无法回答上来的。但如果把搜索引擎作为AI交互的工具，结合react框架，他得到答案的过程可能会是这样，首先针对问题他会思考，要回答这个问题需要去查找赛国信息，这个AI能借助搜索引擎，所以他的后续行动是搜索，搜索关键字是2025 uf ion ion。接下来他开始观察行动带来的结果，也就是得到了一系列包含欧冠信息的网页。针对上一步行动的结果，他开始了新一轮推理。某个新闻网站的链接标题提到了决赛，所以可能包含需要的信息。因此对应这一步的行动就是点进那个链接，进入网页后，他观察到有一段话提到了夺冠球队，并且有决赛对手和比分信息，于是针对这些信息她继续思考，下一步应该进行引用，给用户提供答案。因此最后一步行动就是把查到的信息进行总结，告知用户最终答案。但这还有一个关键问题，模型本身啊只是生成文本搜索点击之类的动作，在这个过程中是怎么做的呢？答案是模型用文字把自己的意图表达成结构化指令后，外部系统会去调用实际的工具来执行，再把结果未回给模型继续推理。比如系统接收到模型输出的搜索2025 uf chaion leachaon后，知道要调用搜索工具了，于是会去实际调用搜索引擎，然后把搜索结果整理成文本返回给模型，接下来模型看到这些观察结果会继续新一轮推理。这样一来一回就形成了推理、行动、观察再推理的循环。通过react可以看到模型一步步接近答案的任务，解决轨迹与人类很相似了。而且react框架的action行动不专指搜索和浏览网页，而是AI模型所支持的任何行动。比如，如果模型可以和代码解释器交互，那运行代码可以被作为行动选项。如果模型可以访问外部文档，那从文档里查找关键字可以被作为行动选项。如果模型可以调用某个应用的api，那和那个应用交互也可以被作为行动选项。用这个系列的科普视频帮助帮助你对生成是AI大约模型等建立了更多认知，了解了豆包拆gp等火爆应用下的技术根基。在他人为层出不穷、眼花缭乱的新应用焦虑时，你能以不变应万变。如果对你有帮助，也别忘了点个赞再走，我们之后再见。</div>
    <div class="back-link">
        <a href="../index.html">← 返回首页</a>
    </div>
</body>
</html>
